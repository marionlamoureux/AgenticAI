{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c502f10c-348d-43d1-9b64-934e055330e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# init notebook setting up the backend. \n",
    "\n",
    "Do not edit the notebook, it contains import and helpers for the demo\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-science&org_id=984752964297111&notebook=%2F_resources%2F00-init-stylist&demo_name=llm-tools-functions&event=VIEW&path=%2F_dbdemos%2Fdata-science%2Fllm-tools-functions%2F_resources%2F00-init-stylist&version=1&user_hash=e61a20ecc22427b72adf9caf8d2fa6358cfdb6b25abd27b2e1fe8d13f9b4226c\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce8e36a9-2567-4764-9365-4ae1827af587",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff0bf0be-4416-46b5-b7ed-7a5ff82482de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ./00-init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be671c4e-265a-4b2e-988d-cc84f74b486c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_exists = False\n",
    "try:\n",
    "  data_exists = spark.catalog.tableExists('tools_orders') and spark.catalog.tableExists('tools_customers')\n",
    "  if data_exists:\n",
    "    data_exists = spark.sql('select count(*) as c from tools_customers where email=current_user').collect()[0]['c'] > 0\n",
    "except Exception as e:\n",
    "  print(f\"folder doesn't exists, generating the data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e73db589-ca21-42d7-ad6d-b56523a0d5f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "    from pyspark.sql import functions as F\n",
    "    from faker import Faker\n",
    "    from collections import OrderedDict \n",
    "    import uuid\n",
    "    fake = Faker()\n",
    "    import random\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    fake_firstname = F.udf(fake.first_name)\n",
    "    fake_lastname = F.udf(fake.last_name)\n",
    "    fake_email = F.udf(fake.ascii_company_email)\n",
    "\n",
    "    def fake_date_between(months=0):\n",
    "        start = datetime.now() - timedelta(days=30*months)\n",
    "        return F.udf(lambda: fake.date_between_dates(date_start=start, date_end=start + timedelta(days=30)).strftime(\"%m-%d-%Y %H:%M:%S\"))\n",
    "\n",
    "    fake_date = F.udf(lambda:fake.date_time_this_month().strftime(\"%m-%d-%Y %H:%M:%S\"))\n",
    "    fake_date_old = F.udf(lambda:fake.date_between_dates(date_start=datetime(2012,1,1), date_end=datetime(2015,12,31)).strftime(\"%m-%d-%Y %H:%M:%S\"))\n",
    "    fake_address = F.udf(fake.address)\n",
    "    canal = OrderedDict([(\"WEBAPP\", 0.5),(\"MOBILE\", 0.1),(\"PHONE\", 0.3),(None, 0.01)])\n",
    "    fake_canal = F.udf(lambda:fake.random_elements(elements=canal, length=1)[0])\n",
    "    fake_id = F.udf(lambda: str(uuid.uuid4()))\n",
    "    countries = ['FR', 'USA', 'SPAIN']\n",
    "    fake_country = F.udf(lambda: countries[random.randint(0,2)])\n",
    "    current_email = spark.sql('select current_user() as email').collect()[0]['email']\n",
    "    def get_df(size, month, id=None):\n",
    "        df = spark.range(0, size).repartition(10)\n",
    "        df = df.withColumn(\"id\", F.lit(id) if id else fake_id())\n",
    "        df = df.withColumn(\"firstname\", fake_firstname())\n",
    "        df = df.withColumn(\"lastname\", fake_lastname())\n",
    "        df = df.withColumn(\"email\", F.lit(current_email) if id else fake_email())\n",
    "        df = df.withColumn(\"address\", fake_address())\n",
    "        df = df.withColumn(\"canal\", fake_canal())\n",
    "        df = df.withColumn(\"country\", fake_country())  \n",
    "        df = df.withColumn(\"creation_date\", fake_date_between(month)())\n",
    "        df = df.withColumn(\"last_activity_date\", fake_date())\n",
    "        return df.withColumn(\"age_group\", F.round(F.rand()*10))\n",
    "\n",
    "    df_customers = get_df(1000, 12*30)\n",
    "    df_customers = df_customers.union(get_df(1, 12*30, id='d8ca793f-7f06-42d3-be1b-929e32fc8bc9'))\n",
    "    #for i in range(1, 24):\n",
    "    #  df_customers = df_customers.union(get_df(2000+i*200, 24-i))\n",
    "\n",
    "    df_customers.write.mode('overwrite').saveAsTable('tools_customers')\n",
    "\n",
    "    ids = spark.read.table(('tools_customers')).select(\"id\").collect()\n",
    "    ids = [r[\"id\"] for r in ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7039615-842f-417c-8d19-80151c969deb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not data_exists:\n",
    "    #Number of order per customer to generate a nicely distributed dataset\n",
    "    import numpy as np\n",
    "    np.random.seed(0)\n",
    "    mu, sigma = 3, 2 # mean and standard deviation\n",
    "    s = np.random.normal(mu, sigma, int(len(ids)))\n",
    "    s = [i if i > 0 else 0 for i in s]\n",
    "\n",
    "    #Most of our customers have ~3 orders\n",
    "    import matplotlib.pyplot as plt\n",
    "    count, bins, ignored = plt.hist(s, 30, density=False)\n",
    "    plt.show()\n",
    "    s = [int(i) for i in s]\n",
    "\n",
    "    order_user_ids = list()\n",
    "    for i, id in enumerate(ids):\n",
    "        order_count = s[i]\n",
    "        if id == 'd8ca793f-7f06-42d3-be1b-929e32fc8bc9':\n",
    "            order_count = 5\n",
    "        for j in range(1, order_count):\n",
    "            order_user_ids.append(id)\n",
    "\n",
    "    print(f\"Generated {len(order_user_ids)} orders for {len(ids)} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d486a734-62b1-49ea-97f8-17256c70d60d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if not data_exists:\n",
    "    # Define the weighted probabilities for the order status\n",
    "    order_status_prob = OrderedDict([(\"Pending\", 0.3), (\"Shipped\", 0.4), (\"Delivered\", 0.25), (\"Cancelled\", 0.05)])\n",
    "\n",
    "    # UDF to generate random order status based on the defined probabilities\n",
    "    fake_order_status = F.udf(lambda: fake.random_elements(elements=order_status_prob, length=1)[0])\n",
    "\n",
    "    orders = spark.createDataFrame([(i,) for i in order_user_ids], ['user_id'])\n",
    "    orders = orders.withColumn(\"id\", fake_id())\n",
    "    orders = orders.withColumn(\"transaction_date\", fake_date())\n",
    "    orders = orders.withColumn(\"item_count\", F.round(F.rand()*2)+1)\n",
    "    orders = orders.withColumn(\"amount\", F.col(\"item_count\")*F.round(F.rand()*30+10))\n",
    "    orders = orders.withColumn(\"order_status\", fake_order_status())  # Add the order status column\n",
    "    orders.write.mode('overwrite').saveAsTable('tools_orders')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00-init-stylist",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
